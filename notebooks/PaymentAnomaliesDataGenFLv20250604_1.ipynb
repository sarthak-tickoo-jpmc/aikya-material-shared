{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127ef6ce41e720d6",
   "metadata": {},
   "source": [
    "# Synthetic Payments Data Generation For Federated Payments Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce15fc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As with any Machine Learning experiment, training and evaluation of models requires good quality datasets. Quality is relative, but generally agreed upon indicators are good data distribution, and a sufficiently large enough number of samples.\n",
    "\n",
    "This is even more pertinent with Federated Learning, as the premise of FL is to be able to train a better model than individual participant models, based on the fact that they individually have been trained on a variety of different distributions. Combined with the lack of good quality data (real-life, partially-synthetic, purely-synthetic) from payment systems, or customizable dataset generators for this domain creates a fundamental problem.\n",
    "\n",
    "We attempt to solve this problem by spinning up a custom purely-synthetic data generation tool. The tool is capable of\n",
    "\n",
    "1. Generating arbitrary number of training and validation datasets.\n",
    "2. Generating data with different distributions which are controllable for repeatability and explain-ability.\n",
    "3. Customizable features and attributes.\n",
    "4. Inducing rule-based anomalies by\n",
    "   1. Enable writing custom rules\n",
    "   2. Enable complex anomaly scenarios via singular complex rules, or via overlapping several simple independent, and compatible rules.\n",
    "   3. Control anomaly class sizes for a variety of scenarios\n",
    "5. Generating datasets for different relevant classification scenarios (binary, multi-label, multi-class), and for different types of models based on their eagerness.\n",
    "\n",
    "\n",
    "## Caveats\n",
    "\n",
    "Even though this tool is fairly flexible, the tool and the data that we generate have their own caveats as it currently stands\n",
    "\n",
    "1. The distribution of the data is completely hypothetical. It is hard to source true payments data distributions, let alone the dataset itself because of strict regulation and privacy control measures. So, the resulting models may not work in the real world simply because the distribution and the class size might be entirely different.\n",
    "2. The dataset inflates the anomaly class samples to avoid minority class problems during data processing. It introduces anomalies into about 25-35% of the records, but in reality payment anomalies constitute < 1% of all the samples in payments datasets. However, this can be adjusted and a datasets with fewer anomalies can be generated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b7673cef03b5bf",
   "metadata": {},
   "source": [
    "## Import Required Modules\n",
    "\n",
    "We start off by importing all the modules that we will need for our synthetic payments data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "\n",
    "os.environ['MPLCONFIGDIR'] = \"~/\"\n",
    "\n",
    "import uuid\n",
    "import logging\n",
    "from logging import config\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "# third-party imports\n",
    "import faker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from babel import numbers\n",
    "from currency_converter import CurrencyConverter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b2c12ec2a84a7",
   "metadata": {},
   "source": [
    "## Static Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dacbe1b2723f34",
   "metadata": {},
   "source": [
    "### Countries and Currencies\n",
    "\n",
    "For CBP datasets, this serves a few purposes\n",
    "\n",
    "1. These countries provide bounds for geo-regions that we add cross border payments data for.\n",
    "2. These countries help find land geo-coordinates which might not correspond to a real address, but are real land geo-coordinates from a country.\n",
    "3. These country codes also help us generate more realistic currency and rates data. Libraries such as `babel` accept countries as `alpha_2` codes to return corresponding real currency codes (`alpha_3` format e.g. `USD`).\n",
    "4. Overall, this gives the whole dataset a more \"realistic\" feel and aligns us to use good quality information when we expand the process to create more realistic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "680b70079548dfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>CAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MX</td>\n",
       "      <td>MXN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BR</td>\n",
       "      <td>BRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GB</td>\n",
       "      <td>GBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FR</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CH</td>\n",
       "      <td>CHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DE</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NL</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TR</td>\n",
       "      <td>TRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RU</td>\n",
       "      <td>RUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>IN</td>\n",
       "      <td>INR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CN</td>\n",
       "      <td>CNY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HK</td>\n",
       "      <td>HKD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JP</td>\n",
       "      <td>JPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KR</td>\n",
       "      <td>KRW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ZA</td>\n",
       "      <td>ZAR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AU</td>\n",
       "      <td>AUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NZ</td>\n",
       "      <td>NZD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   country currency\n",
       "0       US      USD\n",
       "1       CA      CAD\n",
       "2       MX      MXN\n",
       "3       BR      BRL\n",
       "4       GB      GBP\n",
       "5       FR      EUR\n",
       "6       CH      CHF\n",
       "7       DE      EUR\n",
       "8       NL      EUR\n",
       "9       TR      TRY\n",
       "10      RU      RUB\n",
       "11      IN      INR\n",
       "12      CN      CNY\n",
       "13      HK      HKD\n",
       "14      JP      JPY\n",
       "15      KR      KRW\n",
       "16      ZA      ZAR\n",
       "17      AU      AUD\n",
       "18      NZ      NZD"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can use pycountry to get a list of alpha_2 codes for countries of interest. I am hardcoding this list, because sometimes static data generation can become\n",
    "# highly unpredictable. reference data libs do not work predictably always.\n",
    "# it might be something that I am doing but don't have the time right now to fix or debug\n",
    "COUNTRIES = (\n",
    "    \"US\",\n",
    "    \"CA\",\n",
    "    \"MX\",\n",
    "    \"BR\",\n",
    "    \"GB\",\n",
    "    \"FR\",\n",
    "    \"CH\",\n",
    "    \"DE\",\n",
    "    \"NL\",\n",
    "    \"TR\",\n",
    "    \"RU\",\n",
    "    \"IN\",\n",
    "    \"CN\",\n",
    "    \"HK\",\n",
    "    \"JP\",\n",
    "    \"KR\",\n",
    "    \"ZA\",\n",
    "    \"AU\",\n",
    "    \"NZ\",\n",
    ")\n",
    "COUNTRY_STATIC_DATA = pd.DataFrame(\n",
    "    {\n",
    "        \"country\": COUNTRIES,\n",
    "        \"currency\": [numbers.get_territory_currencies(cty)[0] for cty in COUNTRIES],\n",
    "    }\n",
    ")\n",
    "COUNTRY_STATIC_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc285e3299909fa",
   "metadata": {},
   "source": [
    "### Define currency exchange rates\n",
    "\n",
    "We use real-life historic currency exchange rate information to mimic the real-world \"feel\" of the dataset. We can use/generate artificial rates; however, in the spirit of data realism, we leverage the `currency_converter` module to get us some historic rates for currency pairs defined in the previous step from public data published by European Central Bank (ECB).\n",
    "\n",
    "> Since this library under the hood calls a rest endpoint, we need to ensure that we do not call this library unnecessarily. This data though available freely, we want to ensure respectable usage.\n",
    "\n",
    "A few points to note\n",
    "- The function `generate_exchange_rates` fetches rates and saves them to a CSV file. The function defaults to using the static rates file. There is an existing file checked under `/path/to/fl/payments/synthetic-data-gen/data/EXCHANGE_RATES.csv`.\n",
    "- If you wish to force fetch the rates from the API, you must pass the `force_load_from_api` flag to the `generate_exchange_rates` function as `True`.\n",
    "- Be careful that if you do this, it will override the data in the `EXCHANGE_RATES.csv` file which comes with this notebook in the repository.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7648627f72ebf80e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CCY1</th>\n",
       "      <th>CCY2</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USD</td>\n",
       "      <td>CAD</td>\n",
       "      <td>1.3635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USD</td>\n",
       "      <td>MXN</td>\n",
       "      <td>19.6464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USD</td>\n",
       "      <td>BRL</td>\n",
       "      <td>3.8679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USD</td>\n",
       "      <td>GBP</td>\n",
       "      <td>0.7862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CCY1 CCY2     RATE\n",
       "0  USD  USD   1.0000\n",
       "1  USD  CAD   1.3635\n",
       "2  USD  MXN  19.6464\n",
       "3  USD  BRL   3.8679\n",
       "4  USD  GBP   0.7862"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define some exchange rates\n",
    "def generate_exchange_rates(\n",
    "        rates_file_name=\"./data/EXCHANGE_RATES.csv\", force_load_from_api=False\n",
    "):\n",
    "    abs_filepath = os.path.abspath(os.path.expanduser(os.path.expandvars(rates_file_name)))\n",
    "\n",
    "    if force_load_from_api or not os.path.exists(abs_filepath):\n",
    "        os.makedirs(os.path.dirname(abs_filepath), exist_ok=True)\n",
    "        print(\" ==> [WARNING] <== LOADING CURRENCY EXCHANGE RATES FROM API\")\n",
    "\n",
    "        curr_conv = CurrencyConverter(fallback_on_missing_rate=True)\n",
    "        all_ccy_pairs = pd.MultiIndex.from_product(\n",
    "            [COUNTRY_STATIC_DATA[\"currency\"], COUNTRY_STATIC_DATA[\"currency\"]],\n",
    "            names=[\"CCY1\", \"CCY2\"],\n",
    "        ).to_frame(index=False)\n",
    "\n",
    "        def _xchg_rate(row):\n",
    "            rate = (\n",
    "                curr_conv.convert(\n",
    "                    1,\n",
    "                    row[\"CCY1\"],\n",
    "                    row[\"CCY2\"],\n",
    "                    date=date(2019, 1, 1),\n",
    "                )\n",
    "                if row[\"CCY1\"] != row[\"CCY2\"]\n",
    "                else 1\n",
    "            )\n",
    "            return round((1.0 if rate == 0.0 or not rate else rate), 4)\n",
    "\n",
    "        all_ccy_pairs[\"RATE\"] = all_ccy_pairs.loc[:, [\"CCY1\", \"CCY2\"]].apply(\n",
    "            _xchg_rate, axis=1\n",
    "        )\n",
    "        all_ccy_pairs.to_csv(rates_file_name, index=False, mode=\"w\", quotechar='\"')\n",
    "    return pd.read_csv(rates_file_name)\n",
    "\n",
    "\n",
    "# define a helper function which simplifies fetching rates from the rates data frame\n",
    "def get_exchange_rates(curr1, curr2):\n",
    "    result = EXCHANGE_RATES[\n",
    "        (EXCHANGE_RATES[\"CCY1\"] == curr1) & (EXCHANGE_RATES[\"CCY2\"] == curr2)\n",
    "        ]\n",
    "    return result[\"RATE\"].values[0] if len(result) else 1\n",
    "\n",
    "\n",
    "EXCHANGE_RATES: pd.DataFrame = generate_exchange_rates(force_load_from_api=False)\n",
    "EXCHANGE_RATES.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2dc8a9154be17b",
   "metadata": {},
   "source": [
    "### Define reference data\n",
    "\n",
    "Besides the currency and country reference data that we generated earlier, we define a few more constants which will help define the parameters over which data generation will take place.\n",
    "\n",
    "This includes (but not limited to)\n",
    "- Payment participant prefixes\n",
    "- Payment statuses which will be sampled randomly.\n",
    "- Payment transaction types. E.g. could include `REQUEST_FOR_PAYMENT` from creditor to the debitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bc42a75aaedf95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAYMENT_CRDTR_PREFIX = \"CREDITOR\"\n",
    "PAYMENT_DBTR_PREFIX = \"DEBITOR\"\n",
    "PAYMENT_TRANSACTION_TYPES = [\"PAYMENT\"]\n",
    "PAYMENT_STATUS = [\"PENDING\", \"PROCESSING\", \"COMPLETED\", \"FAILED\", \"CANCELLED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70d07acfde6c9c",
   "metadata": {},
   "source": [
    "## Initialize Faker\n",
    "\n",
    "Faker is a python library for generating realistic-looking fake data. It uses a pseudo-random generator backed data provider for those curious.\n",
    "\n",
    "- For the sake of brevity we only use locales which have English as a language. in practice however, data could belong to any locale.\n",
    "- We also peg the seed to a fixed value to ensure that the data generated everytime is the same. But we can avoid this if we want some degree of randomness\n",
    "- Additionally, we weight the data so the data sampled from providers though completely random ascribes to a more normal data distribution.\n",
    "- We also use weighting to generate data out of a distribution to make it more \"realistic\". if you want to randomize data, set `use_weighting=False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30e34afd39b4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "faker.Faker.seed(0)\n",
    "fake: faker.Faker = faker.Faker(locale=[\"en\", \"tr_TR\"], use_weighting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293de7ab-9ade-4943-9eae-56de3317fe6c",
   "metadata": {},
   "source": [
    "## Data Generation Quick Access - Functions to change sampled attributes\n",
    "\n",
    "These functions should help you quickly tune the values of the dataset attribute normal and anomalous values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f62492c-aaf4-4770-898d-9c117f26cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Distribution(str, Enum):\n",
    "    Uniform = \"uniform\"\n",
    "    Normal = \"normal\"\n",
    "\n",
    "\n",
    "def sample_value_from_distribution(dist: Distribution, *args, **kwargs):\n",
    "    if dist == Distribution.Uniform:\n",
    "        if \"low\" not in kwargs or \"high\" not in kwargs:\n",
    "            raise RuntimeError(\n",
    "                \"If uniform distribution, you need to provide distribution intervals as low and high values.\")\n",
    "        return np.random.uniform(low=kwargs[\"low\"], high=kwargs[\"high\"])\n",
    "\n",
    "    elif dist == Distribution.Normal:\n",
    "        if \"mean\" not in kwargs or \"std_dev\" not in kwargs:\n",
    "            raise RuntimeError(\n",
    "                \"If normal distribution, you need to provide distribution parameters as mean and std_dev, where std_dev > 0\")\n",
    "        return np.random.normal(loc=kwargs[\"mean\"], scale=kwargs[\"std_dev\"])\n",
    "\n",
    "    raise RuntimeError(\"Distribution not recognized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449c831cb288d51b",
   "metadata": {},
   "source": [
    "#### CHANGE ME FOR DIFFERENT DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12f6efba39df2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## functions for generating NORMAL tower lat and long. note that this returns a delta, not a absolute value\n",
    "tower_latitude_perturbation_fn = lambda: float(sample_value_from_distribution(Distribution.Uniform, low=-1, high=1))\n",
    "tower_longitude_perturbation_fn = lambda: float(sample_value_from_distribution(Distribution.Uniform, low=-1, high=1))\n",
    "\n",
    "## function for generating tower lat and long perturbance. note that this returns a delta, not a absolute value\n",
    "get_north_or_east_perturbation_factor = lambda: -9.1\n",
    "get_south_or_west_perturbation_factor = lambda: -8.9\n",
    "\n",
    "## function for generating normal debitor amount\n",
    "debitor_amount_generator_fn = lambda: float(\n",
    "    np.round(sample_value_from_distribution(Distribution.Uniform, low=10_000_000, high=20_000_000), 2))\n",
    "\n",
    "## function for generating anomalous debitor amount\n",
    "anomalous_debitor_amount_generator_fn = lambda: float(\n",
    "    np.round(sample_value_from_distribution(Distribution.Uniform, low=15_000_000, high=25_000_000), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646d7cc62c3db1c",
   "metadata": {},
   "source": [
    "## Create dataset attributes template\n",
    "\n",
    "- To keep row data generation as simple as possible and yet be flexible enough, we define the data fields as properties which have a `name` and `value` associated with them. (c.f. `PaymentAttribute`)\n",
    "- We then define parts of the attributes using \n",
    "- We define simple class method interfaces so that we can quickly and uniformly generate data over a concise API.\n",
    "- This API also serves well to generate more complex forms of data with data relationships and dependencies.\n",
    "- We then tie all of this together with a schema based row generator `PaymentRowGenerator` which generates the row using a class method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e90ab85efdb0b4",
   "metadata": {},
   "source": [
    "### Attribute Specifier\n",
    "\n",
    "This class helps represent all attributes as properties, where the name is pre-formatter, but the values are assigned dyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "417c51517d311355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaymentAttribute:\n",
    "    def __init__(self, attr_name: str):\n",
    "        self._name = attr_name.upper()\n",
    "        self._value = None\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "    @value.setter\n",
    "    def value(self, value):\n",
    "        self._value = value\n",
    "\n",
    "    def get_key_value(self):\n",
    "        return self.name, self.value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3e6a6a79761481",
   "metadata": {},
   "source": [
    "### Payment Participant Attributes (attributes common to actors of the payment - DEBITOR and CREDITOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ec50c796ce59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinate(addr_country_code: str) -> float:\n",
    "    # ST - This is annoying. faker.geo.local_latlng accepts a country code to GUARANTEE a coord.\n",
    "    #   however, calling this API is not consistent, and it is prone to return None. my guess as to probably why is that\n",
    "    #   it has an internal marker/ idx over a subset of locations filtered on country. if this marker/ idx falls outside set bounds,\n",
    "    #   it returns none. since this is a random marker, it jumps wildly. a simple loop with 10 tries to fetch\n",
    "    #   10 coords from say US sometimes returns nothing 8/10 times. retrying is the only option.\n",
    "    #   10 seems to be a faithful number of times to try\n",
    "    coord = None\n",
    "    while not coord:\n",
    "        coord = fake.local_latlng(country_code=addr_country_code)\n",
    "\n",
    "    # print(f\"------country: {addr_country}, coord: {coord} -------\")\n",
    "    # idx 0 is lat and 1 is long\n",
    "    return coord\n",
    "\n",
    "\n",
    "class PaymentParticipantAttributes:\n",
    "    def __init__(self, participant_prefix: str):\n",
    "        super().__init__()\n",
    "        self.participant_prefix = participant_prefix\n",
    "        self.username = PaymentAttribute(f\"{self.participant_prefix}_username\")\n",
    "        self.first_name = PaymentAttribute(f\"{self.participant_prefix}_first_name\")\n",
    "        self.last_name = PaymentAttribute(f\"{self.participant_prefix}_last_name\")\n",
    "        self.email_address = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_email_address\"\n",
    "        )\n",
    "        self.phone_number = PaymentAttribute(f\"{self.participant_prefix}_phone_number\")\n",
    "        self.birth_year = PaymentAttribute(f\"{self.participant_prefix}_birth_year\")\n",
    "        self.birth_month = PaymentAttribute(f\"{self.participant_prefix}_birth_month\")\n",
    "        self.birth_day = PaymentAttribute(f\"{self.participant_prefix}_birth_day\")\n",
    "        self.gender = PaymentAttribute(f\"{self.participant_prefix}_gender\")\n",
    "        self.addr_building = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_addr_building\"\n",
    "        )\n",
    "        self.addr_street = PaymentAttribute(f\"{self.participant_prefix}_addr_street\")\n",
    "        self.addr_city = PaymentAttribute(f\"{self.participant_prefix}_addr_city\")\n",
    "        self.addr_state = PaymentAttribute(f\"{self.participant_prefix}_addr_state\")\n",
    "        self.addr_zipcode = PaymentAttribute(f\"{self.participant_prefix}_addr_zipcode\")\n",
    "        self.addr_country = PaymentAttribute(f\"{self.participant_prefix}_addr_country\")\n",
    "        self.geo_latitude = PaymentAttribute(f\"{self.participant_prefix}_geo_latitude\")\n",
    "        self.geo_longitude = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_geo_longitude\"\n",
    "        )\n",
    "        self.account_number = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_account_number\"\n",
    "        )\n",
    "        self.bic_code = PaymentAttribute(f\"{self.participant_prefix}_bic_code\")\n",
    "        self.account_create_timestamp = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_account_create_timestamp\"\n",
    "        )\n",
    "        self.currency = PaymentAttribute(f\"{self.participant_prefix}_currency\")\n",
    "        self.ip_address = PaymentAttribute(f\"{self.participant_prefix}_ip_address\")\n",
    "        self.tower_latitude = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_tower_latitude\"\n",
    "        )\n",
    "        self.tower_longitude = PaymentAttribute(\n",
    "            f\"{self.participant_prefix}_tower_longitude\"\n",
    "        )\n",
    "        self.comment = PaymentAttribute(f\"{self.participant_prefix}_comment\")\n",
    "\n",
    "    def _set_base_data(self):\n",
    "        self.username.value = fake.user_name()\n",
    "        self.first_name.value = fake.first_name()\n",
    "        self.last_name.value = fake.last_name()\n",
    "        self.email_address.value = fake.email()\n",
    "        self.phone_number.value = fake.phone_number()\n",
    "        self.gender.value = str(np.random.choice([\"M\", \"F\", \"NB\"]))\n",
    "\n",
    "    def _set_dates(self):\n",
    "        dob = fake.date_of_birth(minimum_age=21, maximum_age=80)\n",
    "        self.birth_year.value = dob.year\n",
    "        self.birth_month.value = dob.month\n",
    "        self.birth_day.value = dob.day\n",
    "\n",
    "    def _set_account_details(self):\n",
    "        self.account_number.value = fake.iban()\n",
    "        self.bic_code.value = fake.aba()\n",
    "        # \"normal\" accounts are at least 3 months old (relative to today's date)\n",
    "        # NOTE: If you change this - please review PaymentCoreFinancialAttributes.payment_init_timestamp and payment_update_timestamp\n",
    "        self.account_create_timestamp.value = fake.date_time_between(\n",
    "            start_date=datetime(1985, 1, 1, 0, 0, 0),\n",
    "            end_date=(datetime.today() - timedelta(weeks=12)),\n",
    "        ).timestamp()\n",
    "\n",
    "    def _set_address_details(self):\n",
    "        self.addr_building.value = fake.building_number()\n",
    "        self.addr_street.value = f\"{fake.street_name()} {fake.street_suffix()}\"\n",
    "        self.addr_city.value = fake.city()\n",
    "        self.addr_state.value = fake.state()\n",
    "        self.addr_zipcode.value = fake.postcode()\n",
    "        self.addr_country.value = str(np.random.choice(COUNTRIES))\n",
    "        geo_coord = get_coordinate(self.addr_country.value)\n",
    "        self.geo_latitude.value = np.float64(geo_coord[0])\n",
    "        self.geo_longitude.value = np.float64(geo_coord[1])\n",
    "\n",
    "    def _set_operational_details(self):\n",
    "        self.currency.value = COUNTRY_STATIC_DATA[\n",
    "            COUNTRY_STATIC_DATA[\"country\"] == self.addr_country.value\n",
    "            ][\"currency\"].values[0]\n",
    "        self.ip_address.value = fake.ipv4(network=False)\n",
    "        # tower location is typically within +-1 deg N-S and +-1 deg E-W for \"normal\" transactions\n",
    "        # 1 degree lat shift ~ 69 miles and 1 degree long shift ~ 54.6 miles\n",
    "        self.tower_latitude.value = self.geo_latitude.value + tower_latitude_perturbation_fn()\n",
    "        self.tower_longitude.value = self.geo_longitude.value + tower_longitude_perturbation_fn()\n",
    "        self.comment.value = fake.text(max_nb_chars=60)\n",
    "\n",
    "    def set_mock_data(self):\n",
    "        self._set_base_data()\n",
    "        self._set_address_details()\n",
    "        self._set_dates()\n",
    "        self._set_account_details()\n",
    "        self._set_operational_details()\n",
    "\n",
    "    def get_mock_data_row(self) -> dict:\n",
    "        self.set_mock_data()\n",
    "        mock_data_row: dict = {\n",
    "            self.__dict__[item].name: self.__dict__[item].value\n",
    "            for item in self.__dict__\n",
    "            if isinstance(self.__dict__[item], PaymentAttribute)\n",
    "        }\n",
    "        return mock_data_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bfe4d9b5a5a012",
   "metadata": {},
   "source": [
    "### Payment Row Core Financial Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "769cf546111173b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaymentCoreFinancialAttributes:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.payment_id = PaymentAttribute(\"payment_id\")\n",
    "        self.payment_init_timestamp = PaymentAttribute(\"payment_init_timestamp\")\n",
    "        self.payment_last_update_timestamp = PaymentAttribute(\n",
    "            \"payment_last_update_timestamp\"\n",
    "        )\n",
    "        self.payment_status = PaymentAttribute(\"payment_status\")\n",
    "        self.payment_type = PaymentAttribute(\"payment_type\")\n",
    "\n",
    "    def set_mock_data(\n",
    "            self, dbtr: PaymentParticipantAttributes, crdtr: PaymentParticipantAttributes\n",
    "    ):\n",
    "        self.payment_id.value = str(uuid.uuid4())\n",
    "\n",
    "        # compare dbtr acc create and crdtr acc create timestamps, and determine whose account was created later.\n",
    "        latest_ts = datetime.fromtimestamp(\n",
    "            dbtr.account_create_timestamp.value\n",
    "            if dbtr.account_create_timestamp.value\n",
    "               >= crdtr.account_create_timestamp.value\n",
    "            else crdtr.account_create_timestamp.value\n",
    "        )\n",
    "        # the idea here is that \"normal\" transactions will only happen at least 15 days AFTER the users accounts were created.\n",
    "        # since the account age is guaranteed to be at least 3 months old relative to TODAY (check PaymentParticipantAttributes)\n",
    "        # the date generated will never be past today\n",
    "        self.payment_init_timestamp.value = fake.date_time_between(\n",
    "            start_date=(latest_ts + timedelta(days=15)), end_date=datetime.now()\n",
    "        ).timestamp()\n",
    "        self.payment_last_update_timestamp.value = fake.date_time_between(\n",
    "            start_date=datetime.fromtimestamp(\n",
    "                self.payment_last_update_timestamp.value\n",
    "                if self.payment_last_update_timestamp.value\n",
    "                else self.payment_init_timestamp.value\n",
    "            ),\n",
    "            end_date=datetime.now(),\n",
    "        ).timestamp()\n",
    "        self.payment_status.value = str(np.random.choice(PAYMENT_STATUS))\n",
    "        self.payment_type.value = str(np.random.choice(PAYMENT_TRANSACTION_TYPES))\n",
    "\n",
    "    def get_mock_data_row(\n",
    "            self, dbtr: PaymentParticipantAttributes, crdtr: PaymentParticipantAttributes\n",
    "    ) -> dict:\n",
    "        self.set_mock_data(dbtr, crdtr)\n",
    "        mock_data_row: dict = {\n",
    "            self.__dict__[item].name: self.__dict__[item].value\n",
    "            for item in self.__dict__\n",
    "            if isinstance(self.__dict__[item], PaymentAttribute)\n",
    "        }\n",
    "        return mock_data_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b8c59a1349045",
   "metadata": {},
   "source": [
    "### Payment Row Derived Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0923e77d043e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaymentDerivedAttributes:\n",
    "    def __init__(self):\n",
    "        self.dbtr_ccy_crdtr_ccy_rate = PaymentAttribute(\n",
    "            f\"{PAYMENT_DBTR_PREFIX}_ccy_{PAYMENT_CRDTR_PREFIX}_ccy_rate\"\n",
    "        )\n",
    "        self.crdtr_ccy_dbtr_ccy_rate = PaymentAttribute(\n",
    "            f\"{PAYMENT_CRDTR_PREFIX}_ccy_{PAYMENT_DBTR_PREFIX}_ccy_rate\"\n",
    "        )\n",
    "        self.dbtr_amount = PaymentAttribute(f\"{PAYMENT_DBTR_PREFIX}_amount\")\n",
    "        self.crdtr_amount = PaymentAttribute(f\"{PAYMENT_CRDTR_PREFIX}_amount\")\n",
    "\n",
    "    def set_mock_data(\n",
    "            self, dbtr: PaymentParticipantAttributes, crdtr: PaymentParticipantAttributes\n",
    "    ):\n",
    "        self.dbtr_ccy_crdtr_ccy_rate.value = get_exchange_rates(\n",
    "            dbtr.currency.value, crdtr.currency.value\n",
    "        )\n",
    "        self.crdtr_ccy_dbtr_ccy_rate.value = get_exchange_rates(\n",
    "            crdtr.currency.value, dbtr.currency.value\n",
    "        )\n",
    "        self.dbtr_amount.value = debitor_amount_generator_fn()\n",
    "        self.crdtr_amount.value = float(np.round(\n",
    "            self.dbtr_amount.value * self.dbtr_ccy_crdtr_ccy_rate.value, 2\n",
    "        ))\n",
    "\n",
    "    def get_mock_data_row(\n",
    "            self, dbtr: PaymentParticipantAttributes, crdtr: PaymentParticipantAttributes\n",
    "    ) -> dict:\n",
    "        self.set_mock_data(dbtr, crdtr)\n",
    "        mock_data_row: dict = {\n",
    "            self.__dict__[item].name: self.__dict__[item].value\n",
    "            for item in self.__dict__\n",
    "            if isinstance(self.__dict__[item], PaymentAttribute)\n",
    "        }\n",
    "        return mock_data_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d116d987e709c9",
   "metadata": {},
   "source": [
    "### Payment Row Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "577f450ced0f67ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaymentRowGenerator:\n",
    "    dbtr_attributes = PaymentParticipantAttributes(PAYMENT_DBTR_PREFIX)\n",
    "    crdtr_attributes = PaymentParticipantAttributes(PAYMENT_CRDTR_PREFIX)\n",
    "    core_fin_attributes = PaymentCoreFinancialAttributes()\n",
    "    derived_fin_attributes = PaymentDerivedAttributes()\n",
    "\n",
    "    @classmethod\n",
    "    def generate_row(cls):\n",
    "        payment_row: dict = {\"FRAUD_FLAG\": 0}\n",
    "        payment_row.update(cls.dbtr_attributes.get_mock_data_row())\n",
    "        payment_row.update(cls.crdtr_attributes.get_mock_data_row())\n",
    "        payment_row.update(\n",
    "            cls.core_fin_attributes.get_mock_data_row(\n",
    "                dbtr=cls.dbtr_attributes, crdtr=cls.crdtr_attributes\n",
    "            )\n",
    "        )\n",
    "        payment_row.update(\n",
    "            cls.derived_fin_attributes.get_mock_data_row(\n",
    "                dbtr=cls.dbtr_attributes, crdtr=cls.crdtr_attributes\n",
    "            )\n",
    "        )\n",
    "        return payment_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe2602de4c9b45",
   "metadata": {},
   "source": [
    "## Anomaly Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f812c-3415-44ac-902f-fa47e94e5f23",
   "metadata": {},
   "source": [
    "### Define rules for inserting a payment anomalies\n",
    "\n",
    "The way we approach generating anomalous data is by assuming that the base data we generate are \"good\" transactions - which are free of anomalies.\n",
    "We then define perturbative functions to nudge a non-anomalous row to an anomalous one.\n",
    "\n",
    "1. These simple rules are self-contained. They can be applied to a data set to generate very simple and and easily separable classes.\n",
    "2. These rules can be combined to create more complex scenarios where anomaly elements are spread across multiple dimensions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639d4fad5d85c68",
   "metadata": {},
   "source": [
    "### Anomaly Type 1 - Geo Location and Tower Location are too far apart\n",
    "\n",
    "We define a simple rule which will mutate the tower location to be further away from the supposed physical location of a creditor and/or debitor.\n",
    "This is inspired from payment app features where transactions initiated further away from city region where the customer normally operates usually are flagged and considered fraudulent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb7b6004ffa2982",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_faraway_coord(coord, max_coord, min_coord):\n",
    "    # print(coord, max_coord, min_coord)\n",
    "    # first find the leeway we have towards either directions\n",
    "    curr_north_or_east_delta = max_coord - coord + get_north_or_east_perturbation_factor()\n",
    "    curr_south_or_west_delta = abs(min_coord - coord) + get_south_or_west_perturbation_factor()\n",
    "    # print(\"Deltas: \", curr_north_or_east_delta, curr_south_or_west_delta)\n",
    "\n",
    "    # based on the range above, we can generate a coordinate range to move\n",
    "    north_or_east_coord_range = (\n",
    "        (max_coord - curr_north_or_east_delta, max_coord)\n",
    "        if curr_north_or_east_delta > 0\n",
    "        else (0, 0)\n",
    "    )\n",
    "    south_or_west_coord_range = (\n",
    "        (min_coord, curr_south_or_west_delta - abs(min_coord))\n",
    "        if curr_south_or_west_delta > 0\n",
    "        else (0, 0)\n",
    "    )\n",
    "    # print(\"Coord ranges: \", north_or_east_coord_range, south_or_west_coord_range)\n",
    "\n",
    "    new_north_or_east_coord = float(np.random.uniform(*north_or_east_coord_range))\n",
    "    new_south_or_west_coord = float(np.random.uniform(*south_or_west_coord_range))\n",
    "    # print(\"New Coordinates: \", new_north_or_east_coord, new_south_or_west_coord)\n",
    "\n",
    "    if curr_north_or_east_delta > 0 and curr_south_or_west_delta > 0:\n",
    "        return float(np.random.choice((new_north_or_east_coord, new_south_or_west_coord)))\n",
    "    elif curr_north_or_east_delta > 0:\n",
    "        return new_north_or_east_coord\n",
    "    elif curr_south_or_west_delta > 0:\n",
    "        return new_south_or_west_coord\n",
    "\n",
    "\n",
    "def type_1_tower_loc_phy_loc_mismatch(row):\n",
    "    row[\"DEBITOR_TOWER_LATITUDE\"] = generate_faraway_coord(\n",
    "        row[\"DEBITOR_TOWER_LATITUDE\"], 90, -90\n",
    "    )\n",
    "    row[\"DEBITOR_TOWER_LONGITUDE\"] = generate_faraway_coord(\n",
    "        row[\"DEBITOR_TOWER_LONGITUDE\"], 180, -180\n",
    "    )\n",
    "    row[\"CREDITOR_TOWER_LATITUDE\"] = generate_faraway_coord(\n",
    "        row[\"CREDITOR_TOWER_LATITUDE\"], 90, -90\n",
    "    )\n",
    "    row[\"CREDITOR_TOWER_LONGITUDE\"] = generate_faraway_coord(\n",
    "        row[\"CREDITOR_TOWER_LONGITUDE\"], 180, -180\n",
    "    )\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a40c532cd1ae7",
   "metadata": {},
   "source": [
    "### Anomaly Type 2 - Account age is too low and the amount is above a certain threshold\n",
    "\n",
    "We define a simple rule which will mutate the account creation timestamp for the debitor to within a few minutes of the payment.\n",
    "This is inspired from features where Debitors with relatively \"young\" accounts have restrictions in place to ensure that they cannot transfer large sums outright. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b92b549c3991ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_2_account_too_young_amount_above_threshold(row):\n",
    "    payment_create_dt = datetime.fromtimestamp(row[\"PAYMENT_INIT_TIMESTAMP\"])\n",
    "    t = payment_create_dt - timedelta(\n",
    "        hours=int(np.random.choice([0, 1, 2, 3, 4, 5])),\n",
    "        minutes=int(np.random.choice([0, 1, 4, 9, 16, 25])),\n",
    "        seconds=int(np.random.choice([1, 10, 20, 30, 40, 50])),\n",
    "    )\n",
    "\n",
    "    row[\"DEBITOR_ACCOUNT_CREATE_TIMESTAMP\"] = t.timestamp()\n",
    "    row[\"DEBITOR_AMOUNT\"] = anomalous_debitor_amount_generator_fn()\n",
    "    row[\"CREDITOR_AMOUNT\"] = float(np.round(row[\"DEBITOR_AMOUNT\"] * row[\"DEBITOR_CCY_CREDITOR_CCY_RATE\"], 2))\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e996f4-299a-47ec-bb17-2b0e3683f716",
   "metadata": {},
   "source": [
    "### Define anomaly mapping\n",
    "\n",
    "To wrap up the fraud generation mechanism, we define a simple map of these fraud generating functions, and map them to be used later.\n",
    "We also define a function to insert arbitrary fraudulent rows based on certain input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2d26ed1-264b-47e8-afab-59ea93db2999",
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAUD_TYPE_DEFINITION = {\n",
    "    \"type1\": type_1_tower_loc_phy_loc_mismatch,\n",
    "    \"type2\": type_2_account_too_young_amount_above_threshold,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd14804e439d12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_indices_with_controlled_overlap(\n",
    "        dataset_df: pd.DataFrame,\n",
    "        fraudulent_frac: float = 0.3,\n",
    "        random_state=42,\n",
    "        fraud_overlap_frac: float = 0.0,\n",
    "):\n",
    "    existing_fraud_rows = dataset_df[dataset_df[\"FRAUD_FLAG\"] == 1]\n",
    "    existing_non_fraud_rows = dataset_df[dataset_df[\"FRAUD_FLAG\"] == 0]\n",
    "    # if we do not want to overlap fraud rules, then we sample only non-fraud rows\n",
    "    if fraud_overlap_frac <= 0:\n",
    "        return existing_non_fraud_rows.sample(\n",
    "            frac=fraudulent_frac, random_state=random_state\n",
    "        ).index\n",
    "\n",
    "    # if we want to overlap fraud rules, then we sample based on fraud_overlap_frac.\n",
    "    # we subsample the fraud rows by fraud_overlap_frac and select the rest from non-fraud rows\n",
    "    total_fraud_row_count = int(np.ceil(dataset_df.shape[0] * fraudulent_frac))\n",
    "    fraud_subsample_row_count = int(np.ceil(total_fraud_row_count * fraud_overlap_frac))\n",
    "    fraud_subsample_row_count = (\n",
    "        fraud_subsample_row_count\n",
    "        if existing_fraud_rows.shape[0] > fraud_subsample_row_count\n",
    "        else existing_fraud_rows.shape[0]\n",
    "    )\n",
    "    non_fraud_subsample_row_count = total_fraud_row_count - fraud_subsample_row_count\n",
    "    non_fraud_subsample_row_count = (\n",
    "        non_fraud_subsample_row_count\n",
    "        if existing_non_fraud_rows.shape[0] > non_fraud_subsample_row_count\n",
    "        else existing_non_fraud_rows.shape[0]\n",
    "    )\n",
    "    fraud_subsample = existing_fraud_rows.sample(\n",
    "        n=fraud_subsample_row_count, random_state=random_state\n",
    "    )\n",
    "    non_fraud_subsample = existing_non_fraud_rows.sample(\n",
    "        n=non_fraud_subsample_row_count, random_state=random_state\n",
    "    )\n",
    "    return pd.concat([fraud_subsample, non_fraud_subsample]).index\n",
    "\n",
    "\n",
    "def insert_fraud_rows(\n",
    "        fraud_insertion_func,\n",
    "        dataset_df: pd.DataFrame,\n",
    "        fraudulent_frac: float = 0.3,\n",
    "        random_state=42,\n",
    "        fraud_overlap_frac: float = 0.1,\n",
    "):\n",
    "    fraudulent_txn_indexes = get_row_indices_with_controlled_overlap(\n",
    "        dataset_df,\n",
    "        fraudulent_frac,\n",
    "        random_state=random_state,\n",
    "        fraud_overlap_frac=fraud_overlap_frac,\n",
    "    )\n",
    "    # print(fraudulent_txn_indexes)\n",
    "    if fraudulent_txn_indexes.empty:\n",
    "        print(\n",
    "            \"COULD NOT SAMPLE INDEXES BASED ON THE FRAUD FRACTION AND OVERLAP FRACTION!\"\n",
    "        )\n",
    "        return dataset_df\n",
    "\n",
    "    # fraudulent_txn_indexes = dataset_df.sample(frac=fraudulent_frac, random_state=random_state).index\n",
    "    dataset_df.loc[fraudulent_txn_indexes, :] = dataset_df.loc[\n",
    "                                                fraudulent_txn_indexes, :\n",
    "                                                ].apply(fraud_insertion_func, axis=1)\n",
    "    dataset_df.loc[fraudulent_txn_indexes, [\"FRAUD_FLAG\"]] = 1\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073a64d43063d01",
   "metadata": {},
   "source": [
    "## Test Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3ba8f9-3bee-4327-9954-10cb00c04d5f",
   "metadata": {},
   "source": [
    "### Generate Sample Payment Data\n",
    "To see all of what we have defined in action, let us generate some sample rows.\n",
    "We then display this in a simple tabular format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27b125965ed5b726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FRAUD_FLAG', 'DEBITOR_USERNAME', 'DEBITOR_FIRST_NAME',\n",
       "       'DEBITOR_LAST_NAME', 'DEBITOR_EMAIL_ADDRESS', 'DEBITOR_PHONE_NUMBER',\n",
       "       'DEBITOR_BIRTH_YEAR', 'DEBITOR_BIRTH_MONTH', 'DEBITOR_BIRTH_DAY',\n",
       "       'DEBITOR_GENDER', 'DEBITOR_ADDR_BUILDING', 'DEBITOR_ADDR_STREET',\n",
       "       'DEBITOR_ADDR_CITY', 'DEBITOR_ADDR_STATE', 'DEBITOR_ADDR_ZIPCODE',\n",
       "       'DEBITOR_ADDR_COUNTRY', 'DEBITOR_GEO_LATITUDE', 'DEBITOR_GEO_LONGITUDE',\n",
       "       'DEBITOR_ACCOUNT_NUMBER', 'DEBITOR_BIC_CODE',\n",
       "       'DEBITOR_ACCOUNT_CREATE_TIMESTAMP', 'DEBITOR_CURRENCY',\n",
       "       'DEBITOR_IP_ADDRESS', 'DEBITOR_TOWER_LATITUDE',\n",
       "       'DEBITOR_TOWER_LONGITUDE', 'DEBITOR_COMMENT', 'CREDITOR_USERNAME',\n",
       "       'CREDITOR_FIRST_NAME', 'CREDITOR_LAST_NAME', 'CREDITOR_EMAIL_ADDRESS',\n",
       "       'CREDITOR_PHONE_NUMBER', 'CREDITOR_BIRTH_YEAR', 'CREDITOR_BIRTH_MONTH',\n",
       "       'CREDITOR_BIRTH_DAY', 'CREDITOR_GENDER', 'CREDITOR_ADDR_BUILDING',\n",
       "       'CREDITOR_ADDR_STREET', 'CREDITOR_ADDR_CITY', 'CREDITOR_ADDR_STATE',\n",
       "       'CREDITOR_ADDR_ZIPCODE', 'CREDITOR_ADDR_COUNTRY',\n",
       "       'CREDITOR_GEO_LATITUDE', 'CREDITOR_GEO_LONGITUDE',\n",
       "       'CREDITOR_ACCOUNT_NUMBER', 'CREDITOR_BIC_CODE',\n",
       "       'CREDITOR_ACCOUNT_CREATE_TIMESTAMP', 'CREDITOR_CURRENCY',\n",
       "       'CREDITOR_IP_ADDRESS', 'CREDITOR_TOWER_LATITUDE',\n",
       "       'CREDITOR_TOWER_LONGITUDE', 'CREDITOR_COMMENT', 'PAYMENT_ID',\n",
       "       'PAYMENT_INIT_TIMESTAMP', 'PAYMENT_LAST_UPDATE_TIMESTAMP',\n",
       "       'PAYMENT_STATUS', 'PAYMENT_TYPE', 'DEBITOR_CCY_CREDITOR_CCY_RATE',\n",
       "       'CREDITOR_CCY_DEBITOR_CCY_RATE', 'DEBITOR_AMOUNT', 'CREDITOR_AMOUNT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_mock_payment_data(num_payment_rows=1):\n",
    "    return [\n",
    "        PaymentRowGenerator.generate_row()\n",
    "        for _ in range(num_payment_rows if num_payment_rows > 0 else 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "# payments dataset\n",
    "dataset = pd.DataFrame(generate_mock_payment_data(num_payment_rows=10))\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6252d851-1a9e-466f-a4fc-fec431b2d350",
   "metadata": {},
   "source": [
    "### Conditioning generated sample data\n",
    "\n",
    "Before we induce anomalies in this sample dataset, let us condition it a bit we randomize the row order for better predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fa3df446e5841fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling row order...\n",
      "Resetting indexes...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRAUD_FLAG</th>\n",
       "      <th>DEBITOR_USERNAME</th>\n",
       "      <th>DEBITOR_FIRST_NAME</th>\n",
       "      <th>DEBITOR_LAST_NAME</th>\n",
       "      <th>DEBITOR_EMAIL_ADDRESS</th>\n",
       "      <th>DEBITOR_PHONE_NUMBER</th>\n",
       "      <th>DEBITOR_BIRTH_YEAR</th>\n",
       "      <th>DEBITOR_BIRTH_MONTH</th>\n",
       "      <th>DEBITOR_BIRTH_DAY</th>\n",
       "      <th>DEBITOR_GENDER</th>\n",
       "      <th>...</th>\n",
       "      <th>CREDITOR_COMMENT</th>\n",
       "      <th>PAYMENT_ID</th>\n",
       "      <th>PAYMENT_INIT_TIMESTAMP</th>\n",
       "      <th>PAYMENT_LAST_UPDATE_TIMESTAMP</th>\n",
       "      <th>PAYMENT_STATUS</th>\n",
       "      <th>PAYMENT_TYPE</th>\n",
       "      <th>DEBITOR_CCY_CREDITOR_CCY_RATE</th>\n",
       "      <th>CREDITOR_CCY_DEBITOR_CCY_RATE</th>\n",
       "      <th>DEBITOR_AMOUNT</th>\n",
       "      <th>CREDITOR_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anthonyday</td>\n",
       "      <td>Natalie</td>\n",
       "      <td>Tevetoğlu</td>\n",
       "      <td>zerickson@example.com</td>\n",
       "      <td>001-826-727-9061</td>\n",
       "      <td>2002</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Computer doctor up high southern job high.</td>\n",
       "      <td>1979176c-f87f-49c9-b0b7-8ff28e2241d2</td>\n",
       "      <td>1.691787e+09</td>\n",
       "      <td>1.749631e+09</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>4.4185</td>\n",
       "      <td>18765728.51</td>\n",
       "      <td>4.246684e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>kaversezer</td>\n",
       "      <td>Stephen</td>\n",
       "      <td>Rogers</td>\n",
       "      <td>dennis75@example.net</td>\n",
       "      <td>(992)466 1093</td>\n",
       "      <td>1964</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Blanditiis id dignissimos aliquam veniam.</td>\n",
       "      <td>d805a55c-7b03-41a3-bd4d-ba977d182df0</td>\n",
       "      <td>1.748336e+09</td>\n",
       "      <td>1.730731e+09</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>0.5864</td>\n",
       "      <td>1.7052</td>\n",
       "      <td>13180665.40</td>\n",
       "      <td>7.729142e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>temizkalcetin</td>\n",
       "      <td>Öge</td>\n",
       "      <td>Clark</td>\n",
       "      <td>uzbaybilge@example.com</td>\n",
       "      <td>952-240-5980x250</td>\n",
       "      <td>1976</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>NB</td>\n",
       "      <td>...</td>\n",
       "      <td>Provident inventore consequuntur ab maiores.</td>\n",
       "      <td>41523862-e624-4406-8bb2-e3016e9426e1</td>\n",
       "      <td>1.140835e+09</td>\n",
       "      <td>1.749295e+09</td>\n",
       "      <td>COMPLETED</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>3.9072</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>14561646.70</td>\n",
       "      <td>5.689527e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>qturk</td>\n",
       "      <td>Ünübol</td>\n",
       "      <td>Güçlü</td>\n",
       "      <td>fayizeyaman@example.com</td>\n",
       "      <td>001-719-848-9241x15781</td>\n",
       "      <td>1958</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Garden economy others kind.</td>\n",
       "      <td>daf401da-852a-41f7-a4d3-c88ff3cfcc18</td>\n",
       "      <td>1.612870e+09</td>\n",
       "      <td>1.727436e+09</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>77.5460</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>14508788.97</td>\n",
       "      <td>1.125099e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>yilmazcagdan</td>\n",
       "      <td>Gücal</td>\n",
       "      <td>Martin</td>\n",
       "      <td>sherryvilla@example.com</td>\n",
       "      <td>960.733.4523x5326</td>\n",
       "      <td>1991</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>NB</td>\n",
       "      <td>...</td>\n",
       "      <td>Popular word book read pass heart soldier action.</td>\n",
       "      <td>7185f035-6632-4314-9509-57f9b1903263</td>\n",
       "      <td>1.703913e+09</td>\n",
       "      <td>1.749616e+09</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>8.9484</td>\n",
       "      <td>10566916.26</td>\n",
       "      <td>1.181381e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>hakgunduz</td>\n",
       "      <td>Turcein</td>\n",
       "      <td>Karadeniz</td>\n",
       "      <td>qsener@example.org</td>\n",
       "      <td>4558508249</td>\n",
       "      <td>1985</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Ut doloremque consequuntur.</td>\n",
       "      <td>f3bec399-2cb8-4127-84bd-e94608a0d332</td>\n",
       "      <td>9.081038e+08</td>\n",
       "      <td>1.734211e+09</td>\n",
       "      <td>PROCESSING</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1118.9434</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>11801660.79</td>\n",
       "      <td>1.320539e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>sierra14</td>\n",
       "      <td>Heather</td>\n",
       "      <td>Gray</td>\n",
       "      <td>salizorlu@example.net</td>\n",
       "      <td>+1-717-418-7727</td>\n",
       "      <td>1972</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NB</td>\n",
       "      <td>...</td>\n",
       "      <td>Choice phone nor. Western month itself history.</td>\n",
       "      <td>148ee983-8929-4615-823a-9aa94fc12b79</td>\n",
       "      <td>1.561908e+09</td>\n",
       "      <td>1.749632e+09</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>80.2934</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>13195452.69</td>\n",
       "      <td>1.059508e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>cynthiapitts</td>\n",
       "      <td>Bariş</td>\n",
       "      <td>Hall</td>\n",
       "      <td>demirelfugen@example.com</td>\n",
       "      <td>708 8 697</td>\n",
       "      <td>1964</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>NB</td>\n",
       "      <td>...</td>\n",
       "      <td>Nulla ad nisi laudantium.</td>\n",
       "      <td>30dcbdcb-4eee-49b3-a9fe-819fb3976939</td>\n",
       "      <td>1.608652e+09</td>\n",
       "      <td>1.748563e+09</td>\n",
       "      <td>PROCESSING</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>8.9484</td>\n",
       "      <td>11832526.22</td>\n",
       "      <td>1.322876e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>fergusonkyle</td>\n",
       "      <td>Filit</td>\n",
       "      <td>Brock</td>\n",
       "      <td>necmettininonu@example.org</td>\n",
       "      <td>(602)906 1126</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>Corporis ut corporis et distinctio deleniti.</td>\n",
       "      <td>e554c6c3-d608-4194-8ffa-6f7cfa38aa8b</td>\n",
       "      <td>1.547128e+09</td>\n",
       "      <td>1.748186e+09</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>2.1009</td>\n",
       "      <td>12256402.94</td>\n",
       "      <td>5.834048e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>uyildirim</td>\n",
       "      <td>Ashley</td>\n",
       "      <td>Hill</td>\n",
       "      <td>durduaygonenc@example.org</td>\n",
       "      <td>+90(132)716-6446x5951</td>\n",
       "      <td>1999</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>NB</td>\n",
       "      <td>...</td>\n",
       "      <td>Similique modi illo quos.</td>\n",
       "      <td>d7b2e2e4-816f-4221-aacd-d81a6641c191</td>\n",
       "      <td>1.346524e+09</td>\n",
       "      <td>1.749348e+09</td>\n",
       "      <td>FAILED</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>79.5371</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>15868036.71</td>\n",
       "      <td>1.262098e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   FRAUD_FLAG DEBITOR_USERNAME DEBITOR_FIRST_NAME DEBITOR_LAST_NAME  \\\n",
       "0           0       anthonyday            Natalie         Tevetoğlu   \n",
       "1           0       kaversezer            Stephen            Rogers   \n",
       "2           0    temizkalcetin                Öge             Clark   \n",
       "3           0            qturk             Ünübol             Güçlü   \n",
       "4           0     yilmazcagdan              Gücal            Martin   \n",
       "5           0        hakgunduz            Turcein         Karadeniz   \n",
       "6           0         sierra14            Heather              Gray   \n",
       "7           0     cynthiapitts              Bariş              Hall   \n",
       "8           0     fergusonkyle              Filit             Brock   \n",
       "9           0        uyildirim             Ashley              Hill   \n",
       "\n",
       "        DEBITOR_EMAIL_ADDRESS    DEBITOR_PHONE_NUMBER  DEBITOR_BIRTH_YEAR  \\\n",
       "0       zerickson@example.com        001-826-727-9061                2002   \n",
       "1        dennis75@example.net           (992)466 1093                1964   \n",
       "2      uzbaybilge@example.com        952-240-5980x250                1976   \n",
       "3     fayizeyaman@example.com  001-719-848-9241x15781                1958   \n",
       "4     sherryvilla@example.com       960.733.4523x5326                1991   \n",
       "5          qsener@example.org              4558508249                1985   \n",
       "6       salizorlu@example.net         +1-717-418-7727                1972   \n",
       "7    demirelfugen@example.com               708 8 697                1964   \n",
       "8  necmettininonu@example.org           (602)906 1126                2001   \n",
       "9   durduaygonenc@example.org   +90(132)716-6446x5951                1999   \n",
       "\n",
       "   DEBITOR_BIRTH_MONTH  DEBITOR_BIRTH_DAY DEBITOR_GENDER  ...  \\\n",
       "0                    3                 10              F  ...   \n",
       "1                    1                  1              F  ...   \n",
       "2                    6                 19             NB  ...   \n",
       "3                   10                  5              F  ...   \n",
       "4                    9                 15             NB  ...   \n",
       "5                    2                 26              M  ...   \n",
       "6                   12                 12             NB  ...   \n",
       "7                   10                 24             NB  ...   \n",
       "8                    8                  1              F  ...   \n",
       "9                    9                 12             NB  ...   \n",
       "\n",
       "                                    CREDITOR_COMMENT  \\\n",
       "0         Computer doctor up high southern job high.   \n",
       "1          Blanditiis id dignissimos aliquam veniam.   \n",
       "2       Provident inventore consequuntur ab maiores.   \n",
       "3                        Garden economy others kind.   \n",
       "4  Popular word book read pass heart soldier action.   \n",
       "5                        Ut doloremque consequuntur.   \n",
       "6    Choice phone nor. Western month itself history.   \n",
       "7                          Nulla ad nisi laudantium.   \n",
       "8       Corporis ut corporis et distinctio deleniti.   \n",
       "9                          Similique modi illo quos.   \n",
       "\n",
       "                             PAYMENT_ID PAYMENT_INIT_TIMESTAMP  \\\n",
       "0  1979176c-f87f-49c9-b0b7-8ff28e2241d2           1.691787e+09   \n",
       "1  d805a55c-7b03-41a3-bd4d-ba977d182df0           1.748336e+09   \n",
       "2  41523862-e624-4406-8bb2-e3016e9426e1           1.140835e+09   \n",
       "3  daf401da-852a-41f7-a4d3-c88ff3cfcc18           1.612870e+09   \n",
       "4  7185f035-6632-4314-9509-57f9b1903263           1.703913e+09   \n",
       "5  f3bec399-2cb8-4127-84bd-e94608a0d332           9.081038e+08   \n",
       "6  148ee983-8929-4615-823a-9aa94fc12b79           1.561908e+09   \n",
       "7  30dcbdcb-4eee-49b3-a9fe-819fb3976939           1.608652e+09   \n",
       "8  e554c6c3-d608-4194-8ffa-6f7cfa38aa8b           1.547128e+09   \n",
       "9  d7b2e2e4-816f-4221-aacd-d81a6641c191           1.346524e+09   \n",
       "\n",
       "  PAYMENT_LAST_UPDATE_TIMESTAMP PAYMENT_STATUS PAYMENT_TYPE  \\\n",
       "0                  1.749631e+09         FAILED      PAYMENT   \n",
       "1                  1.730731e+09        PENDING      PAYMENT   \n",
       "2                  1.749295e+09      COMPLETED      PAYMENT   \n",
       "3                  1.727436e+09         FAILED      PAYMENT   \n",
       "4                  1.749616e+09         FAILED      PAYMENT   \n",
       "5                  1.734211e+09     PROCESSING      PAYMENT   \n",
       "6                  1.749632e+09        PENDING      PAYMENT   \n",
       "7                  1.748563e+09     PROCESSING      PAYMENT   \n",
       "8                  1.748186e+09         FAILED      PAYMENT   \n",
       "9                  1.749348e+09         FAILED      PAYMENT   \n",
       "\n",
       "   DEBITOR_CCY_CREDITOR_CCY_RATE  CREDITOR_CCY_DEBITOR_CCY_RATE  \\\n",
       "0                         0.2263                         4.4185   \n",
       "1                         0.5864                         1.7052   \n",
       "2                         3.9072                         0.2559   \n",
       "3                        77.5460                         0.0129   \n",
       "4                         0.1118                         8.9484   \n",
       "5                      1118.9434                         0.0009   \n",
       "6                        80.2934                         0.0125   \n",
       "7                         0.1118                         8.9484   \n",
       "8                         0.4760                         2.1009   \n",
       "9                        79.5371                         0.0126   \n",
       "\n",
       "  DEBITOR_AMOUNT CREDITOR_AMOUNT  \n",
       "0    18765728.51    4.246684e+06  \n",
       "1    13180665.40    7.729142e+06  \n",
       "2    14561646.70    5.689527e+07  \n",
       "3    14508788.97    1.125099e+09  \n",
       "4    10566916.26    1.181381e+06  \n",
       "5    11801660.79    1.320539e+10  \n",
       "6    13195452.69    1.059508e+09  \n",
       "7    11832526.22    1.322876e+06  \n",
       "8    12256402.94    5.834048e+06  \n",
       "9    15868036.71    1.262098e+09  \n",
       "\n",
       "[10 rows x 60 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the row order randomly\n",
    "print(\"Shuffling row order...\")\n",
    "dataset = dataset.sample(frac=1, replace=False, random_state=42)\n",
    "\n",
    "# post shuffling, previous indexes are preserved. let us trash them and generate new ones.\n",
    "print(\"Resetting indexes...\")\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3713d-3fef-49c9-9a17-f89ae3c6f924",
   "metadata": {},
   "source": [
    "### Explore the anomalous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224eacece85922bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRAUD_FLAG</th>\n",
       "      <th>DEBITOR_TOWER_LATITUDE</th>\n",
       "      <th>DEBITOR_TOWER_LONGITUDE</th>\n",
       "      <th>CREDITOR_TOWER_LATITUDE</th>\n",
       "      <th>CREDITOR_TOWER_LONGITUDE</th>\n",
       "      <th>DEBITOR_ACCOUNT_CREATE_TIMESTAMP</th>\n",
       "      <th>DEBITOR_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-19.666333</td>\n",
       "      <td>-44.283454</td>\n",
       "      <td>52.379328</td>\n",
       "      <td>7.846328</td>\n",
       "      <td>7.800880e+08</td>\n",
       "      <td>18765728.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-44.041372</td>\n",
       "      <td>171.673782</td>\n",
       "      <td>51.710423</td>\n",
       "      <td>5.903726</td>\n",
       "      <td>1.633097e+09</td>\n",
       "      <td>13180665.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>44.719465</td>\n",
       "      <td>-73.591908</td>\n",
       "      <td>38.219670</td>\n",
       "      <td>28.675109</td>\n",
       "      <td>7.937726e+08</td>\n",
       "      <td>14561646.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-28.003750</td>\n",
       "      <td>31.765801</td>\n",
       "      <td>34.996994</td>\n",
       "      <td>128.614218</td>\n",
       "      <td>7.067142e+08</td>\n",
       "      <td>14508788.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.812854</td>\n",
       "      <td>113.107726</td>\n",
       "      <td>48.126139</td>\n",
       "      <td>2.535672</td>\n",
       "      <td>1.161613e+09</td>\n",
       "      <td>10566916.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>45.174548</td>\n",
       "      <td>-123.779113</td>\n",
       "      <td>37.015912</td>\n",
       "      <td>129.358294</td>\n",
       "      <td>5.523917e+08</td>\n",
       "      <td>11801660.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>43.909447</td>\n",
       "      <td>-79.664648</td>\n",
       "      <td>37.828868</td>\n",
       "      <td>140.802051</td>\n",
       "      <td>5.331977e+08</td>\n",
       "      <td>13195452.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>23.299002</td>\n",
       "      <td>114.533494</td>\n",
       "      <td>51.204337</td>\n",
       "      <td>5.946537</td>\n",
       "      <td>9.098445e+08</td>\n",
       "      <td>11832526.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-27.808292</td>\n",
       "      <td>29.079701</td>\n",
       "      <td>40.386313</td>\n",
       "      <td>121.589550</td>\n",
       "      <td>1.258558e+09</td>\n",
       "      <td>12256402.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>52.584392</td>\n",
       "      <td>8.617212</td>\n",
       "      <td>45.871595</td>\n",
       "      <td>38.758100</td>\n",
       "      <td>6.801200e+08</td>\n",
       "      <td>15868036.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FRAUD_FLAG  DEBITOR_TOWER_LATITUDE  DEBITOR_TOWER_LONGITUDE  \\\n",
       "0           0              -19.666333               -44.283454   \n",
       "1           0              -44.041372               171.673782   \n",
       "2           0               44.719465               -73.591908   \n",
       "3           0              -28.003750                31.765801   \n",
       "4           0               22.812854               113.107726   \n",
       "5           0               45.174548              -123.779113   \n",
       "6           0               43.909447               -79.664648   \n",
       "7           0               23.299002               114.533494   \n",
       "8           0              -27.808292                29.079701   \n",
       "9           0               52.584392                 8.617212   \n",
       "\n",
       "   CREDITOR_TOWER_LATITUDE  CREDITOR_TOWER_LONGITUDE  \\\n",
       "0                52.379328                  7.846328   \n",
       "1                51.710423                  5.903726   \n",
       "2                38.219670                 28.675109   \n",
       "3                34.996994                128.614218   \n",
       "4                48.126139                  2.535672   \n",
       "5                37.015912                129.358294   \n",
       "6                37.828868                140.802051   \n",
       "7                51.204337                  5.946537   \n",
       "8                40.386313                121.589550   \n",
       "9                45.871595                 38.758100   \n",
       "\n",
       "   DEBITOR_ACCOUNT_CREATE_TIMESTAMP  DEBITOR_AMOUNT  \n",
       "0                      7.800880e+08     18765728.51  \n",
       "1                      1.633097e+09     13180665.40  \n",
       "2                      7.937726e+08     14561646.70  \n",
       "3                      7.067142e+08     14508788.97  \n",
       "4                      1.161613e+09     10566916.26  \n",
       "5                      5.523917e+08     11801660.79  \n",
       "6                      5.331977e+08     13195452.69  \n",
       "7                      9.098445e+08     11832526.22  \n",
       "8                      1.258558e+09     12256402.94  \n",
       "9                      6.801200e+08     15868036.71  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\n",
    "    [\n",
    "        \"FRAUD_FLAG\",\n",
    "        \"DEBITOR_TOWER_LATITUDE\",\n",
    "        \"DEBITOR_TOWER_LONGITUDE\",\n",
    "        \"CREDITOR_TOWER_LATITUDE\",\n",
    "        \"CREDITOR_TOWER_LONGITUDE\",\n",
    "        \"DEBITOR_ACCOUNT_CREATE_TIMESTAMP\",\n",
    "        \"DEBITOR_AMOUNT\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13de4d44fedcb37",
   "metadata": {},
   "source": [
    "### Test with sample dataset\n",
    "\n",
    "Let us to a sample fraud data generation exercise where we apply these transformations to the same data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "182d1d1816134428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRAUD_FLAG</th>\n",
       "      <th>DEBITOR_TOWER_LATITUDE</th>\n",
       "      <th>DEBITOR_TOWER_LONGITUDE</th>\n",
       "      <th>CREDITOR_TOWER_LATITUDE</th>\n",
       "      <th>CREDITOR_TOWER_LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-19.666333</td>\n",
       "      <td>-44.283454</td>\n",
       "      <td>52.379328</td>\n",
       "      <td>7.846328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-44.041372</td>\n",
       "      <td>171.673782</td>\n",
       "      <td>51.710423</td>\n",
       "      <td>5.903726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.136469</td>\n",
       "      <td>-125.451734</td>\n",
       "      <td>12.767367</td>\n",
       "      <td>-118.149713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-28.003750</td>\n",
       "      <td>31.765801</td>\n",
       "      <td>34.996994</td>\n",
       "      <td>128.614218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>22.812854</td>\n",
       "      <td>113.107726</td>\n",
       "      <td>48.126139</td>\n",
       "      <td>2.535672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>45.174548</td>\n",
       "      <td>-123.779113</td>\n",
       "      <td>37.015912</td>\n",
       "      <td>129.358294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>43.909447</td>\n",
       "      <td>-79.664648</td>\n",
       "      <td>37.828868</td>\n",
       "      <td>140.802051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>23.299002</td>\n",
       "      <td>114.533494</td>\n",
       "      <td>51.204337</td>\n",
       "      <td>5.946537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>-27.808292</td>\n",
       "      <td>29.079701</td>\n",
       "      <td>40.386313</td>\n",
       "      <td>121.589550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-22.444291</td>\n",
       "      <td>149.739651</td>\n",
       "      <td>88.369248</td>\n",
       "      <td>9.468436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FRAUD_FLAG  DEBITOR_TOWER_LATITUDE  DEBITOR_TOWER_LONGITUDE  \\\n",
       "0           0              -19.666333               -44.283454   \n",
       "1           0              -44.041372               171.673782   \n",
       "2           1               26.136469              -125.451734   \n",
       "3           0              -28.003750                31.765801   \n",
       "4           0               22.812854               113.107726   \n",
       "5           0               45.174548              -123.779113   \n",
       "6           0               43.909447               -79.664648   \n",
       "7           0               23.299002               114.533494   \n",
       "8           0              -27.808292                29.079701   \n",
       "9           1              -22.444291               149.739651   \n",
       "\n",
       "   CREDITOR_TOWER_LATITUDE  CREDITOR_TOWER_LONGITUDE  \n",
       "0                52.379328                  7.846328  \n",
       "1                51.710423                  5.903726  \n",
       "2                12.767367               -118.149713  \n",
       "3                34.996994                128.614218  \n",
       "4                48.126139                  2.535672  \n",
       "5                37.015912                129.358294  \n",
       "6                37.828868                140.802051  \n",
       "7                51.204337                  5.946537  \n",
       "8                40.386313                121.589550  \n",
       "9                88.369248                  9.468436  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = insert_fraud_rows(\n",
    "    FRAUD_TYPE_DEFINITION[\"type1\"],\n",
    "    dataset, fraudulent_frac=0.2,\n",
    "    random_state=int(np.random.randint(1, 50)),\n",
    ")\n",
    "dataset[[\"FRAUD_FLAG\", \"DEBITOR_TOWER_LATITUDE\", \"DEBITOR_TOWER_LONGITUDE\", \"CREDITOR_TOWER_LATITUDE\",\n",
    "         \"CREDITOR_TOWER_LONGITUDE\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b913dbbc4acdb7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FRAUD_FLAG</th>\n",
       "      <th>DEBITOR_ACCOUNT_CREATE_TIMESTAMP</th>\n",
       "      <th>DEBITOR_AMOUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.800880e+08</td>\n",
       "      <td>18765728.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.748317e+09</td>\n",
       "      <td>24392322.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>7.937726e+08</td>\n",
       "      <td>14561646.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7.067142e+08</td>\n",
       "      <td>14508788.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.161613e+09</td>\n",
       "      <td>10566916.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>5.523917e+08</td>\n",
       "      <td>11801660.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>5.331977e+08</td>\n",
       "      <td>13195452.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>9.098445e+08</td>\n",
       "      <td>11832526.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1.258558e+09</td>\n",
       "      <td>12256402.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1.346523e+09</td>\n",
       "      <td>22135176.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FRAUD_FLAG  DEBITOR_ACCOUNT_CREATE_TIMESTAMP  DEBITOR_AMOUNT\n",
       "0           0                      7.800880e+08     18765728.51\n",
       "1           1                      1.748317e+09     24392322.74\n",
       "2           1                      7.937726e+08     14561646.70\n",
       "3           0                      7.067142e+08     14508788.97\n",
       "4           0                      1.161613e+09     10566916.26\n",
       "5           0                      5.523917e+08     11801660.79\n",
       "6           0                      5.331977e+08     13195452.69\n",
       "7           0                      9.098445e+08     11832526.22\n",
       "8           0                      1.258558e+09     12256402.94\n",
       "9           1                      1.346523e+09     22135176.93"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = insert_fraud_rows(\n",
    "    FRAUD_TYPE_DEFINITION[\"type2\"], dataset, fraudulent_frac=0.2, fraud_overlap_frac=0.3\n",
    ")\n",
    "dataset[[\"FRAUD_FLAG\", \"DEBITOR_ACCOUNT_CREATE_TIMESTAMP\", \"DEBITOR_AMOUNT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c00597723ecc7",
   "metadata": {},
   "source": [
    "As one can see that specific data transformations to convert a payment transaction row to a fraudulent one are successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610379942ed46a37",
   "metadata": {},
   "source": [
    "## Putting Everything Together\n",
    "\n",
    "We can now combine all the elements developed to generate fraud datasets for mock participating institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0d20e84c2cfdedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_fraud_rules = {\n",
    "    \"bank2\": [\n",
    "        {\n",
    "            \"fraud_insertion_rule_stack\": [],\n",
    "            \"num_datasets\": 2,\n",
    "            # \"min_num_rows\": 2500,\n",
    "            \"max_num_rows\": 2500,\n",
    "        },\n",
    "        # Genesis dataset with Type 1 frauds for bank 1\n",
    "        {\n",
    "            \"fraud_insertion_rule_stack\": [\"type1\"],\n",
    "            \"num_datasets\": 2,\n",
    "            # \"min_num_rows\": 25000,\n",
    "            \"max_num_rows\": 25000,\n",
    "            \"apply_probability\": 0.9,\n",
    "            \"fname_label\": \"gen_train\",\n",
    "        },\n",
    "        {\n",
    "            \"fraud_insertion_rule_stack\": [\"type1\"],\n",
    "            \"num_datasets\": 1,\n",
    "            \"apply_probability\": 0.9,\n",
    "            \"fname_label\": \"scaling\",\n",
    "            \"min_num_rows\": 2500,\n",
    "            \"max_num_rows\": 2500,\n",
    "        },\n",
    "        {\n",
    "            \"fraud_insertion_rule_stack\": [\"type2\"],\n",
    "            \"num_datasets\": 1,\n",
    "            \"apply_probability\": 0.9,\n",
    "            \"fname_label\": \"scaling\",\n",
    "            \"min_num_rows\": 2500,\n",
    "            \"max_num_rows\": 2500,\n",
    "        },\n",
    "        # for eval set for bank1\n",
    "        {\n",
    "            \"fraud_insertion_rule_stack\": [\"type1\"],\n",
    "            \"num_datasets\": 5,\n",
    "            \"apply_probability\": 0.9,\n",
    "            \"fname_label\": \"eval\",\n",
    "            \"min_num_rows\": 2500,\n",
    "            \"max_num_rows\": 2500,\n",
    "        },\n",
    "        {\n",
    "            \"fraud_insertion_rule_stack\": [\"type2\"],\n",
    "            \"num_datasets\": 5,\n",
    "            \"apply_probability\": 0.9,\n",
    "            \"fname_label\": \"eval\",\n",
    "            \"min_num_rows\": 2500,\n",
    "            \"max_num_rows\": 2500,\n",
    "        }\n",
    "        # {\n",
    "        #     \"fraud_insertion_rule_stack\": [\"type1\", \"type2\"],\n",
    "        #     \"num_datasets\": 1,\n",
    "        #     \"apply_probability\": 0.9,\n",
    "        #     \"fname_label\": \"eval\",\n",
    "        #     \"min_num_rows\": 2500,\n",
    "        #     \"max_num_rows\": 2500,\n",
    "        # },\n",
    "        # {\n",
    "        #     \"fraud_insertion_rule_stack\": [\"type1\", \"type2\"],\n",
    "        #     \"num_datasets\": 1,\n",
    "        #     \"apply_probability\": 0.9,\n",
    "        #     \"fraud_overlap_frac\": 0.33,\n",
    "        #     \"fname_label\": \"eval\",\n",
    "        #     \"min_num_rows\": 2500,\n",
    "        #     \"max_num_rows\": 2500,\n",
    "        # },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d749df0fd6f790",
   "metadata": {},
   "source": [
    "### Define a map of banks to the rule set for data generation\n",
    "\n",
    "This can then be looped over in a repeatable pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8537945d103a428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fraud_with_probability(\n",
    "        dataset_df: pd.DataFrame, fraud_apply_probability: float = 0.9\n",
    ") -> pd.DataFrame:\n",
    "    # we want to confuse the model just a bit by giving some rows fraud like values, but they might not actually be fraudulent\n",
    "    # if we want to apply fraud with a 100% probability, then just return\n",
    "    if fraud_apply_probability >= 1:\n",
    "        return dataset_df\n",
    "\n",
    "    # we want to take 1 - fraud_apply_probability fraction of rows and then sift through them\n",
    "    # select rows where we induced fraud\n",
    "    fraud_rows_idx = (\n",
    "        dataset_df[dataset_df[\"FRAUD_FLAG\"] == 1]\n",
    "        .sample(frac=(1 - fraud_apply_probability), random_state=38)\n",
    "        .index\n",
    "    )\n",
    "    # then, reset the fraud flag value for some rows\n",
    "    dataset_df.loc[fraud_rows_idx, \"FRAUD_FLAG\"] = dataset_df.loc[\n",
    "        fraud_rows_idx, \"FRAUD_FLAG\"\n",
    "    ].apply(lambda _: 1 - _)\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f71cec9b0ce51",
   "metadata": {},
   "source": [
    "### Define quick logging utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38128427975309d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter-sarthakt/data_generation_stats.log'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file_path = os.path.join(\n",
    "    os.path.abspath(os.path.expanduser(os.path.expandvars(\"./\"))),\n",
    "    \"data_generation_stats.log\",\n",
    ")\n",
    "log_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a603071975923e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dict_config = {\n",
    "    \"version\": 1,\n",
    "    # \"disable_existing_loggers\": True, # enable if third-party logging is annoying\n",
    "    \"formatters\": {\n",
    "        \"defaultFormatter\": {\n",
    "            \"format\": \"[%(asctime)s] [%(levelname)s] [%(threadName)s] - %(message)s\"\n",
    "        }\n",
    "    },\n",
    "    \"handlers\": {\n",
    "        \"console\": {\n",
    "            \"class\": \"logging.StreamHandler\",\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"defaultFormatter\",\n",
    "            \"stream\": \"ext://sys.stdout\",\n",
    "        },\n",
    "        \"file\": {\n",
    "            \"class\": \"logging.FileHandler\",\n",
    "            \"level\": \"INFO\",\n",
    "            \"formatter\": \"defaultFormatter\",\n",
    "            \"filename\": log_file_path,\n",
    "        },\n",
    "    },\n",
    "    \"loggers\": {\"\": {\"level\": \"INFO\", \"handlers\": [\"console\", \"file\"]}},  # root logger\n",
    "}\n",
    "logging.config.dictConfig(logging_dict_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84f3e3ea9a5a4d",
   "metadata": {},
   "source": [
    "### Generate all bank data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f1ebfee572ef83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make dataset directory\n",
    "dir_path = os.path.abspath(os.path.expanduser(os.path.expandvars(\"./payment_anom_datasets_experiment_1\")))\n",
    "os.makedirs(dir_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d3f66c29a2655fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-11 10:49:27,192] [INFO] [MainThread] - ------------------------------------------------------------\n",
      "[2025-06-11 10:49:27,193] [INFO] [MainThread] - Starting data generation...\n",
      "[2025-06-11 10:49:27,194] [INFO] [MainThread] - Generating 6 dataset group(s) for bank2...\n",
      "[2025-06-11 10:49:27,195] [INFO] [MainThread] - Generating 2 datasets for bank2 in group 0...\n",
      "[2025-06-11 10:49:27,195] [INFO] [MainThread] - Generating dataset '1' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:49:36,151] [INFO] [MainThread] - Fraud rows: 0\n",
      "[2025-06-11 10:49:36,152] [INFO] [MainThread] - Fraud rows adjusted for application probability: 0\n",
      "[2025-06-11 10:49:36,261] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[no_fraud]_[app_frac_1]_[no_overlap]_[1].csv\n",
      "[2025-06-11 10:49:36,262] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:49:36,262] [INFO] [MainThread] - Generating dataset '2' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:49:45,237] [INFO] [MainThread] - Fraud rows: 0\n",
      "[2025-06-11 10:49:45,238] [INFO] [MainThread] - Fraud rows adjusted for application probability: 0\n",
      "[2025-06-11 10:49:45,352] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[no_fraud]_[app_frac_1]_[no_overlap]_[2].csv\n",
      "[2025-06-11 10:49:45,353] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:49:45,354] [INFO] [MainThread] - Generating 2 datasets for bank2 in group 1...\n",
      "[2025-06-11 10:49:45,354] [INFO] [MainThread] - Generating dataset '1' with '25000' payment rows for 'bank2'...\n",
      "[2025-06-11 10:51:15,218] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:51:15,219] [INFO] [MainThread] - 37%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:51:15,219] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:51:17,184] [INFO] [MainThread] - Fraud rows: 9332\n",
      "[2025-06-11 10:51:17,209] [INFO] [MainThread] - Fraud rows adjusted for application probability: 8399\n",
      "[2025-06-11 10:51:18,407] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_1].csv\n",
      "[2025-06-11 10:51:18,408] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:51:18,408] [INFO] [MainThread] - Generating dataset '2' with '25000' payment rows for 'bank2'...\n",
      "[2025-06-11 10:52:48,096] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:52:48,097] [INFO] [MainThread] - 37%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:52:48,098] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:52:50,076] [INFO] [MainThread] - Fraud rows: 9196\n",
      "[2025-06-11 10:52:50,106] [INFO] [MainThread] - Fraud rows adjusted for application probability: 8276\n",
      "[2025-06-11 10:52:51,298] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_2].csv\n",
      "[2025-06-11 10:52:51,298] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:52:51,299] [INFO] [MainThread] - Generating 1 datasets for bank2 in group 2...\n",
      "[2025-06-11 10:52:51,299] [INFO] [MainThread] - Generating dataset '1' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:00,013] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:00,014] [INFO] [MainThread] - 36%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:53:00,015] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:00,205] [INFO] [MainThread] - Fraud rows: 896\n",
      "[2025-06-11 10:53:00,209] [INFO] [MainThread] - Fraud rows adjusted for application probability: 806\n",
      "[2025-06-11 10:53:00,329] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv\n",
      "[2025-06-11 10:53:00,330] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:00,330] [INFO] [MainThread] - Generating 1 datasets for bank2 in group 3...\n",
      "[2025-06-11 10:53:00,331] [INFO] [MainThread] - Generating dataset '1' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:09,253] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:09,254] [INFO] [MainThread] - 35%' fraudulent rows will be induced by fraud rule 'type2'\n",
      "[2025-06-11 10:53:09,254] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:09,408] [INFO] [MainThread] - Fraud rows: 872\n",
      "[2025-06-11 10:53:09,413] [INFO] [MainThread] - Fraud rows adjusted for application probability: 785\n",
      "[2025-06-11 10:53:09,522] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type2]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv\n",
      "[2025-06-11 10:53:09,523] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:09,523] [INFO] [MainThread] - Generating 5 datasets for bank2 in group 4...\n",
      "[2025-06-11 10:53:09,523] [INFO] [MainThread] - Generating dataset '1' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:18,431] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:18,432] [INFO] [MainThread] - 37%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:53:18,433] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:18,623] [INFO] [MainThread] - Fraud rows: 930\n",
      "[2025-06-11 10:53:18,627] [INFO] [MainThread] - Fraud rows adjusted for application probability: 837\n",
      "[2025-06-11 10:53:18,739] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_1].csv\n",
      "[2025-06-11 10:53:18,740] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:18,740] [INFO] [MainThread] - Generating dataset '2' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:27,652] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:27,653] [INFO] [MainThread] - 30%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:53:27,653] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:27,849] [INFO] [MainThread] - Fraud rows: 752\n",
      "[2025-06-11 10:53:27,853] [INFO] [MainThread] - Fraud rows adjusted for application probability: 677\n",
      "[2025-06-11 10:53:27,969] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_2].csv\n",
      "[2025-06-11 10:53:27,969] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:27,970] [INFO] [MainThread] - Generating dataset '3' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:36,861] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:36,862] [INFO] [MainThread] - 32%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:53:36,862] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:37,030] [INFO] [MainThread] - Fraud rows: 797\n",
      "[2025-06-11 10:53:37,034] [INFO] [MainThread] - Fraud rows adjusted for application probability: 717\n",
      "[2025-06-11 10:53:37,143] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_3].csv\n",
      "[2025-06-11 10:53:37,144] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:37,144] [INFO] [MainThread] - Generating dataset '4' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:46,078] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:46,079] [INFO] [MainThread] - 33%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:53:46,079] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:46,252] [INFO] [MainThread] - Fraud rows: 820\n",
      "[2025-06-11 10:53:46,257] [INFO] [MainThread] - Fraud rows adjusted for application probability: 738\n",
      "[2025-06-11 10:53:46,370] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_4].csv\n",
      "[2025-06-11 10:53:46,370] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:46,371] [INFO] [MainThread] - Generating dataset '5' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:53:55,287] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:53:55,288] [INFO] [MainThread] - 32%' fraudulent rows will be induced by fraud rule 'type1'\n",
      "[2025-06-11 10:53:55,288] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:53:55,461] [INFO] [MainThread] - Fraud rows: 792\n",
      "[2025-06-11 10:53:55,465] [INFO] [MainThread] - Fraud rows adjusted for application probability: 713\n",
      "[2025-06-11 10:53:55,579] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_5].csv\n",
      "[2025-06-11 10:53:55,580] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:53:55,580] [INFO] [MainThread] - Generating 5 datasets for bank2 in group 5...\n",
      "[2025-06-11 10:53:55,580] [INFO] [MainThread] - Generating dataset '1' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:54:04,494] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:54:04,495] [INFO] [MainThread] - 36%' fraudulent rows will be induced by fraud rule 'type2'\n",
      "[2025-06-11 10:54:04,495] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:54:04,659] [INFO] [MainThread] - Fraud rows: 906\n",
      "[2025-06-11 10:54:04,664] [INFO] [MainThread] - Fraud rows adjusted for application probability: 815\n",
      "[2025-06-11 10:54:04,773] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_1].csv\n",
      "[2025-06-11 10:54:04,773] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:54:04,774] [INFO] [MainThread] - Generating dataset '2' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:54:13,708] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:54:13,709] [INFO] [MainThread] - 39%' fraudulent rows will be induced by fraud rule 'type2'\n",
      "[2025-06-11 10:54:13,710] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:54:13,930] [INFO] [MainThread] - Fraud rows: 979\n",
      "[2025-06-11 10:54:13,935] [INFO] [MainThread] - Fraud rows adjusted for application probability: 881\n",
      "[2025-06-11 10:54:14,054] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_2].csv\n",
      "[2025-06-11 10:54:14,055] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:54:14,055] [INFO] [MainThread] - Generating dataset '3' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:54:22,957] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:54:22,958] [INFO] [MainThread] - 34%' fraudulent rows will be induced by fraud rule 'type2'\n",
      "[2025-06-11 10:54:22,958] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:54:23,108] [INFO] [MainThread] - Fraud rows: 841\n",
      "[2025-06-11 10:54:23,112] [INFO] [MainThread] - Fraud rows adjusted for application probability: 757\n",
      "[2025-06-11 10:54:23,224] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_3].csv\n",
      "[2025-06-11 10:54:23,225] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:54:23,225] [INFO] [MainThread] - Generating dataset '4' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:54:32,133] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:54:32,134] [INFO] [MainThread] - 35%' fraudulent rows will be induced by fraud rule 'type2'\n",
      "[2025-06-11 10:54:32,134] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:54:32,289] [INFO] [MainThread] - Fraud rows: 883\n",
      "[2025-06-11 10:54:32,294] [INFO] [MainThread] - Fraud rows adjusted for application probability: 795\n",
      "[2025-06-11 10:54:32,407] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_4].csv\n",
      "[2025-06-11 10:54:32,408] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:54:32,408] [INFO] [MainThread] - Generating dataset '5' with '2500' payment rows for 'bank2'...\n",
      "[2025-06-11 10:54:41,330] [INFO] [MainThread] - Starting fraudulent row insertion... \n",
      "[2025-06-11 10:54:41,331] [INFO] [MainThread] - 35%' fraudulent rows will be induced by fraud rule 'type2'\n",
      "[2025-06-11 10:54:41,331] [INFO] [MainThread] - Will only select previously non-fraudulent rows to sample from...\n",
      "[2025-06-11 10:54:41,491] [INFO] [MainThread] - Fraud rows: 885\n",
      "[2025-06-11 10:54:41,495] [INFO] [MainThread] - Fraud rows adjusted for application probability: 797\n",
      "[2025-06-11 10:54:41,616] [INFO] [MainThread] - Saved data to /home/jupyter-sarthakt/payment_anom_datasets_experiment_1/bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_5].csv\n",
      "[2025-06-11 10:54:41,617] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:54:41,617] [INFO] [MainThread] - Finished dataset generation!\n",
      "[2025-06-11 10:54:41,618] [INFO] [MainThread] - -----------------------------------------------------------\n",
      "[2025-06-11 10:54:41,618] [INFO] [MainThread] - ALL DATASETS PLACED IN THE DIRECTORY: /home/jupyter-sarthakt/payment_anom_datasets_experiment_1\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"------------------------------------------------------------\")\n",
    "logging.info(f\"Starting data generation...\")\n",
    "for bank_name in bank_fraud_rules:\n",
    "    logging.info(\n",
    "        f\"Generating {len(bank_fraud_rules[bank_name])} dataset group(s) for {bank_name}...\"\n",
    "    )\n",
    "\n",
    "    for idx, dataset_gen_config in enumerate(bank_fraud_rules[bank_name]):\n",
    "        fraud_insertion_rule_stack = dataset_gen_config[\"fraud_insertion_rule_stack\"]\n",
    "        num_datasets = dataset_gen_config[\"num_datasets\"]\n",
    "        fraud_overlap_fraction = (\n",
    "            dataset_gen_config[\"fraud_overlap_frac\"]\n",
    "            if \"fraud_overlap_frac\" in dataset_gen_config\n",
    "            else -1\n",
    "        )\n",
    "        min_num_rows = (\n",
    "            dataset_gen_config[\"min_num_rows\"]\n",
    "            if \"min_num_rows\" in dataset_gen_config\n",
    "               and dataset_gen_config[\"min_num_rows\"]\n",
    "            else 1000\n",
    "        )\n",
    "        max_num_rows = (\n",
    "            dataset_gen_config[\"max_num_rows\"]\n",
    "            if \"max_num_rows\" in dataset_gen_config\n",
    "               and dataset_gen_config[\"max_num_rows\"]\n",
    "            else 3000\n",
    "        )\n",
    "        fname_label = (\n",
    "            dataset_gen_config[\"fname_label\"]\n",
    "            if \"fname_label\" in dataset_gen_config and dataset_gen_config[\"fname_label\"]\n",
    "            else \"\"\n",
    "        )\n",
    "        apply_probability = (\n",
    "            dataset_gen_config[\"apply_probability\"]\n",
    "            if \"apply_probability\" in dataset_gen_config\n",
    "               and dataset_gen_config[\"apply_probability\"]\n",
    "            else 1\n",
    "        )\n",
    "\n",
    "        logging.info(\n",
    "            f\"Generating {num_datasets} datasets for {bank_name} in group {idx}...\"\n",
    "        )\n",
    "\n",
    "        for i in range(1, num_datasets + 1):\n",
    "            num_rows = max_num_rows  #int(np.random.randint(min_num_rows, max_num_rows))\n",
    "            logging.info(\n",
    "                f\"Generating dataset '{i}' with '{num_rows}' payment rows for '{bank_name}'...\"\n",
    "            )\n",
    "            bank_dataset: pd.DataFrame = pd.DataFrame(\n",
    "                generate_mock_payment_data(num_payment_rows=num_rows)\n",
    "            )\n",
    "            bank_dataset = bank_dataset.sample(frac=1, replace=False, random_state=42)\n",
    "            bank_dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "            for fraud_type in fraud_insertion_rule_stack:\n",
    "                # if we apply more than 1 fraud rules, we can't sample >30% for every rule given how we generate fraud rows\n",
    "                # in our case specifically, it ends up generating > 50% fraud rows which is not great.\n",
    "                # so we cap the amount of fraud if we apply more than 1 rule\n",
    "                fraud_row_frac = (\n",
    "                    float(np.random.uniform(0.3, 0.4))\n",
    "                    if len(fraud_insertion_rule_stack) == 1\n",
    "                    else float(np.random.uniform(0.15, 0.25))\n",
    "                )\n",
    "                logging.info(\"Starting fraudulent row insertion... \")\n",
    "                logging.info(\n",
    "                    f\"{round(fraud_row_frac * 100)}%' fraudulent rows will be induced by fraud rule '{fraud_type}'\"\n",
    "                )\n",
    "                if fraud_overlap_fraction > 0:\n",
    "                    logging.info(\n",
    "                        f\"Approximately {round(fraud_overlap_fraction * 100)}% previously generated fraud rows will re-sampled\"\n",
    "                    )\n",
    "                else:\n",
    "                    logging.info(\n",
    "                        \"Will only select previously non-fraudulent rows to sample from...\"\n",
    "                    )\n",
    "\n",
    "                bank_dataset = insert_fraud_rows(\n",
    "                    FRAUD_TYPE_DEFINITION[fraud_type],\n",
    "                    bank_dataset,\n",
    "                    fraudulent_frac=fraud_row_frac,\n",
    "                    random_state=int(np.random.randint(20, 50)),\n",
    "                    fraud_overlap_frac=fraud_overlap_fraction,\n",
    "                )\n",
    "\n",
    "            logging.info(\n",
    "                f\"Fraud rows: {bank_dataset[bank_dataset[\"FRAUD_FLAG\"] == 1].shape[0]}\"\n",
    "            )\n",
    "            bank_dataset = apply_fraud_with_probability(bank_dataset, apply_probability)\n",
    "            logging.info(\n",
    "                f\"Fraud rows adjusted for application probability: {bank_dataset[bank_dataset[\"FRAUD_FLAG\"] == 1].shape[0]}\"\n",
    "            )\n",
    "            fname_part_fraud_type = (\n",
    "                \"_\".join(fraud_insertion_rule_stack)\n",
    "                if fraud_insertion_rule_stack\n",
    "                else \"no_fraud\"\n",
    "            )\n",
    "            fname_part_label = f\"{fname_label}_{i}\" if fname_label else i\n",
    "            fname_part_overlap = (\n",
    "                f\"pct_overlap_{round(fraud_overlap_fraction * 100)}\"\n",
    "                if fraud_overlap_fraction > 0\n",
    "                else \"no_overlap\"\n",
    "            )\n",
    "            fname_part_apply_probability = f\"app_frac_{apply_probability}\"\n",
    "\n",
    "            dataset_file_name = os.path.join(\n",
    "                dir_path,\n",
    "                f\"{bank_name}_[{fname_part_fraud_type}]_[{fname_part_apply_probability}]_[{fname_part_overlap}]_[{fname_part_label}].csv\",\n",
    "            )\n",
    "            bank_dataset.to_csv(dataset_file_name, index=False)\n",
    "\n",
    "            logging.info(f\"Saved data to {dataset_file_name}\")\n",
    "            logging.info(\"-----------------------------------------------------------\")\n",
    "\n",
    "logging.info(f\"Finished dataset generation!\")\n",
    "logging.info(\"-----------------------------------------------------------\")\n",
    "logging.info(\"ALL DATASETS PLACED IN THE DIRECTORY: %s\", dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b060eb900fbc405",
   "metadata": {},
   "source": [
    "### Add a summary of all files generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5e60b50707394e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Column Count</th>\n",
       "      <th>Total Rows</th>\n",
       "      <th>Fraudulent Rows</th>\n",
       "      <th>% Fraudulent Rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bank1_[no_fraud]_[app_frac_1]_[no_overlap]_[1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bank1_[no_fraud]_[app_frac_1]_[no_overlap]_[2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>823</td>\n",
       "      <td>32.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>777</td>\n",
       "      <td>31.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_3].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>815</td>\n",
       "      <td>32.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_4].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>676</td>\n",
       "      <td>27.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_5].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>887</td>\n",
       "      <td>35.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>25000</td>\n",
       "      <td>7943</td>\n",
       "      <td>31.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>25000</td>\n",
       "      <td>8463</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bank1_[type1]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>875</td>\n",
       "      <td>35.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>850</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>846</td>\n",
       "      <td>33.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_3].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>784</td>\n",
       "      <td>31.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_4].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>758</td>\n",
       "      <td>30.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_5].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>839</td>\n",
       "      <td>33.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bank1_[type2]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>798</td>\n",
       "      <td>31.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bank2_[no_fraud]_[app_frac_1]_[no_overlap]_[1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bank2_[no_fraud]_[app_frac_1]_[no_overlap]_[2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>837</td>\n",
       "      <td>33.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>677</td>\n",
       "      <td>27.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_3].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>717</td>\n",
       "      <td>28.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_4].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>738</td>\n",
       "      <td>29.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_5].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>713</td>\n",
       "      <td>28.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>25000</td>\n",
       "      <td>8399</td>\n",
       "      <td>33.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>25000</td>\n",
       "      <td>8276</td>\n",
       "      <td>33.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>bank2_[type1]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>806</td>\n",
       "      <td>32.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>815</td>\n",
       "      <td>32.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_2].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>881</td>\n",
       "      <td>35.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_3].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>757</td>\n",
       "      <td>30.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_4].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>795</td>\n",
       "      <td>31.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_5].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>797</td>\n",
       "      <td>31.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>bank2_[type2]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv</td>\n",
       "      <td>60</td>\n",
       "      <td>2500</td>\n",
       "      <td>785</td>\n",
       "      <td>31.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      File Name  Column Count  \\\n",
       "0   bank1_[no_fraud]_[app_frac_1]_[no_overlap]_[1].csv           60             \n",
       "1   bank1_[no_fraud]_[app_frac_1]_[no_overlap]_[2].csv           60             \n",
       "2   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_1].csv       60             \n",
       "3   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_2].csv       60             \n",
       "4   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_3].csv       60             \n",
       "5   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_4].csv       60             \n",
       "6   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[eval_5].csv       60             \n",
       "7   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_1].csv  60             \n",
       "8   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_2].csv  60             \n",
       "9   bank1_[type1]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv    60             \n",
       "10  bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_1].csv       60             \n",
       "11  bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_2].csv       60             \n",
       "12  bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_3].csv       60             \n",
       "13  bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_4].csv       60             \n",
       "14  bank1_[type2]_[app_frac_0.9]_[no_overlap]_[eval_5].csv       60             \n",
       "15  bank1_[type2]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv    60             \n",
       "16  bank2_[no_fraud]_[app_frac_1]_[no_overlap]_[1].csv           60             \n",
       "17  bank2_[no_fraud]_[app_frac_1]_[no_overlap]_[2].csv           60             \n",
       "18  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_1].csv       60             \n",
       "19  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_2].csv       60             \n",
       "20  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_3].csv       60             \n",
       "21  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_4].csv       60             \n",
       "22  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[eval_5].csv       60             \n",
       "23  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_1].csv  60             \n",
       "24  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[gen_train_2].csv  60             \n",
       "25  bank2_[type1]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv    60             \n",
       "26  bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_1].csv       60             \n",
       "27  bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_2].csv       60             \n",
       "28  bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_3].csv       60             \n",
       "29  bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_4].csv       60             \n",
       "30  bank2_[type2]_[app_frac_0.9]_[no_overlap]_[eval_5].csv       60             \n",
       "31  bank2_[type2]_[app_frac_0.9]_[no_overlap]_[scaling_1].csv    60             \n",
       "\n",
       "    Total Rows  Fraudulent Rows  % Fraudulent Rows  \n",
       "0   2500        0                0.00               \n",
       "1   2500        0                0.00               \n",
       "2   2500        823              32.92              \n",
       "3   2500        777              31.08              \n",
       "4   2500        815              32.60              \n",
       "5   2500        676              27.04              \n",
       "6   2500        887              35.48              \n",
       "7   25000       7943             31.77              \n",
       "8   25000       8463             33.85              \n",
       "9   2500        875              35.00              \n",
       "10  2500        850              34.00              \n",
       "11  2500        846              33.84              \n",
       "12  2500        784              31.36              \n",
       "13  2500        758              30.32              \n",
       "14  2500        839              33.56              \n",
       "15  2500        798              31.92              \n",
       "16  2500        0                0.00               \n",
       "17  2500        0                0.00               \n",
       "18  2500        837              33.48              \n",
       "19  2500        677              27.08              \n",
       "20  2500        717              28.68              \n",
       "21  2500        738              29.52              \n",
       "22  2500        713              28.52              \n",
       "23  25000       8399             33.60              \n",
       "24  25000       8276             33.10              \n",
       "25  2500        806              32.24              \n",
       "26  2500        815              32.60              \n",
       "27  2500        881              35.24              \n",
       "28  2500        757              30.28              \n",
       "29  2500        795              31.80              \n",
       "30  2500        797              31.88              \n",
       "31  2500        785              31.40              "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = []\n",
    "dataset_filenames = sorted(os.listdir(dir_path))\n",
    "for dataset_filename in dataset_filenames:\n",
    "    filepath = os.path.join(dir_path, dataset_filename)\n",
    "    if os.path.isfile(filepath):\n",
    "        df = pd.read_csv(filepath)\n",
    "        stats.append([\n",
    "            dataset_filename,\n",
    "            df.shape[1],\n",
    "            df.shape[0],\n",
    "            df[df[\"FRAUD_FLAG\"] == 1].shape[0],\n",
    "            round((df[df[\"FRAUD_FLAG\"] == 1].shape[0] / df.shape[0]) * 100, 2),\n",
    "        ])\n",
    "\n",
    "stats_table = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"File Name\",\n",
    "        \"Column Count\",\n",
    "        \"Total Rows\",\n",
    "        \"Fraudulent Rows\",\n",
    "        \"% Fraudulent Rows\",\n",
    "    ],\n",
    "    data=stats\n",
    ")\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "# stats_table.style.set_properties(subset=['File Name'], **{'width-min': '1000px'})\n",
    "stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1272f-db10-4788-9df9-488f84dcde57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43433457-ae24-402a-b477-046aa61748ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcdfc35-82a1-4597-b746-9931bedc1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "buffer = io.StringIO()\n",
    "dataset.info(buf=buffer)\n",
    "s = buffer.getvalue()\n",
    "with open(\"df_info.txt\", \"w\",\n",
    "          encoding=\"utf-8\") as f:  \n",
    "    f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10164e-c072-406c-aace-8bab6ef4683b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
